{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Sf9LUZGEBMp_"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and Functions"
      ],
      "metadata": {
        "id": "ebnT8KBHKU_1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-ks6Gl-C7PI"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "from PIL import Image\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "from sklearn import preprocessing\n",
        "import pandas as pd\n",
        "from skimage import color\n",
        "from skimage import io\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from skimage.transform import rescale, resize, downscale_local_mean \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from sklearn.metrics import accuracy_score\n",
        "import math\n",
        "\n",
        "import numpy as np \n",
        "from sklearn import datasets, metrics, model_selection, svm\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "np.random.seed(42)\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D , BatchNormalization , Dropout\n",
        "from skimage.color import gray2rgb\n",
        "from keras.preprocessing import image\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def drawing_conf_matrix(  y_actual , y_predict ):\n",
        "    \n",
        "    print( \"Classification Report\" )\n",
        "    print ( classification_report(  y_actual , y_predict  )  )  # to represent accuacy, precision, recall and f1 score\n",
        "\n",
        "    conf_mat = confusion_matrix( y_actual,   y_predict )   # to represent confusion matrix ( TP , FP , FN , FN )\n",
        "  \n",
        "    print( \"Confusion Matrix\")\n",
        "    print( conf_mat )\n",
        "    \n",
        "    sns.heatmap( conf_mat , annot= True  , fmt = \"\" )\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "\n",
        "def readData(path):\n",
        "    dataset =[]\n",
        "    for imagge in glob.glob(path):\n",
        "\n",
        "        #, target_size=(32, 32)\n",
        "        myImage = tf.keras.utils.load_img(imagge, target_size=(32, 32))\n",
        "        # convert the image pixels to a numpy array\n",
        "        image = tf.keras.utils.img_to_array(myImage)\n",
        "        \n",
        "        image = image.reshape((  image.shape[0], image.shape[1], image.shape[2] ))\n",
        "\n",
        "        from keras.applications.vgg16 import preprocess_input\n",
        "        # prepare the image for the VGG model\n",
        "        image = preprocess_input(image)\n",
        "\n",
        "        dataset.append(image)\n",
        "        \n",
        "        \n",
        "    return dataset"
      ],
      "metadata": {
        "id": "UWTmC1N0C_9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from skimage import io\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "   \n",
        "    rotation_range=45,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "  \n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest',\n",
        "   \n",
        ")\n",
        "\n",
        "\n",
        "def augmentData (data , path):\n",
        "\n",
        "  i = 0\n",
        "  for batch in datagen.flow(data,batch_size = 16 ,\n",
        "                          save_to_dir = path,\n",
        "                          save_format = 'png'):\n",
        "    i+=1\n",
        "    if i > 100:\n",
        "      break\n",
        "\n"
      ],
      "metadata": {
        "id": "l1KcdHjWDB22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training Data**"
      ],
      "metadata": {
        "id": "kxXTH4p_J7EJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Data"
      ],
      "metadata": {
        "id": "Sv2j0Ww2DFFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "path1Hundrednote = \"/content/drive/MyDrive/Currency/Train/1Hundrednote/*.*\"\n",
        "path2Hundrednote = \"/content/drive/MyDrive/Currency/Train/2Hundrednote/*.*\"\n",
        "path2Thousandnote = \"/content/drive/MyDrive/Currency/Train/2Thousandnote/*.*\"\n",
        "path5Hundrednote = \"/content/drive/MyDrive/Currency/Train/5Hundrednote/*.*\"\n",
        "pathFiftynote = \"/content/drive/MyDrive/Currency/Train/Fiftynote/*.*\"\n",
        "pathTennote = \"/content/drive/MyDrive/Currency/Train/Tennote/*.*\"\n",
        "pathTwentynote = \"/content/drive/MyDrive/Currency/Train/Twentynote/*.*\"\n",
        "\n",
        "\n",
        "#Training Data  \n",
        "trainingdata1 = readData(path1Hundrednote)\n",
        "trainingdata2 = readData(path2Hundrednote)\n",
        "trainingdata3 = readData(path2Thousandnote)\n",
        "trainingdata4 = readData(path5Hundrednote)\n",
        "trainingdata5 = readData(pathFiftynote)\n",
        "trainingdata6 = readData(pathTennote)\n",
        "trainingdata7 = readData(pathTwentynote)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "allData =[trainingdata1,trainingdata2,trainingdata3,trainingdata4,trainingdata5 ,trainingdata6 , trainingdata7 ]\n",
        "\n",
        "for i in allData : \n",
        "  print(len(i))"
      ],
      "metadata": {
        "id": "GNhKV_VFDIjR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfe68285-9118-441c-feec-4cf85c56c784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n",
            "22\n",
            "21\n",
            "22\n",
            "22\n",
            "22\n",
            "22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AUG Training data"
      ],
      "metadata": {
        "id": "49L6EKeJ9s1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainingdata1 = np.array(trainingdata1)\n",
        "trainingdata2 = np.array(trainingdata2)\n",
        "trainingdata3 = np.array(trainingdata3)\n",
        "trainingdata4 = np.array(trainingdata4)\n",
        "trainingdata5 = np.array(trainingdata5)\n",
        "trainingdata6 = np.array(trainingdata6)\n",
        "trainingdata7 = np.array(trainingdata7)\n",
        "\n",
        "\n",
        "\n",
        "augmentData(trainingdata1 ,\"/content/drive/MyDrive/Currency/AUG Train/1\" )\n",
        "augmentData(trainingdata2 ,\"/content/drive/MyDrive/Currency/AUG Train/2\" )\n",
        "augmentData(trainingdata3 ,\"/content/drive/MyDrive/Currency/AUG Train/3\" )\n",
        "augmentData(trainingdata4 ,\"/content/drive/MyDrive/Currency/AUG Train/4\" )\n",
        "augmentData(trainingdata5 ,\"/content/drive/MyDrive/Currency/AUG Train/5\" )\n",
        "augmentData(trainingdata6 ,\"/content/drive/MyDrive/Currency/AUG Train/6\" )\n",
        "augmentData(trainingdata7 ,\"/content/drive/MyDrive/Currency/AUG Train/7\" )"
      ],
      "metadata": {
        "id": "ACnr3E8iZo3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Length of new Training data**"
      ],
      "metadata": {
        "id": "sLYifMpeACRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainingdata1 = readData(\"/content/drive/MyDrive/Currency/AUG Train/1/*.*\")\n",
        "trainingdata2 = readData(\"/content/drive/MyDrive/Currency/AUG Train/2/*.*\")\n",
        "trainingdata3 = readData(\"/content/drive/MyDrive/Currency/AUG Train/3/*.*\")\n",
        "trainingdata4 = readData(\"/content/drive/MyDrive/Currency/AUG Train/4/*.*\")\n",
        "trainingdata5 = readData(\"/content/drive/MyDrive/Currency/AUG Train/5/*.*\")\n",
        "trainingdata6 = readData(\"/content/drive/MyDrive/Currency/AUG Train/6/*.*\")\n",
        "trainingdata7 = readData(\"/content/drive/MyDrive/Currency/AUG Train/7/*.*\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "allData =[trainingdata1,trainingdata2,trainingdata3,trainingdata4,trainingdata5 ,trainingdata6 , trainingdata7 ]\n",
        "\n",
        "for i in allData : \n",
        "  print(len(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qv1I0yEOAJqd",
        "outputId": "d66f35f2-e0a7-4416-d063-e486637b645c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1113\n",
            "1116\n",
            "1063\n",
            "1114\n",
            "1114\n",
            "1114\n",
            "1111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5459\n",
        "5446\n",
        "5199\n",
        "5439\n",
        "5439\n",
        "5439\n",
        "5437"
      ],
      "metadata": {
        "id": "bnN0bFQgWQZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum = 0 \n",
        "for i in allData : \n",
        "  sum+=len(i)\n",
        "\n",
        "print(sum)"
      ],
      "metadata": {
        "id": "eMZoiCkiAwav",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "124c5db7-b2b0-4aee-b2de-24df2f796128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Data"
      ],
      "metadata": {
        "id": "Sf9LUZGEBMp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "path1Hundrednote = \"/content/drive/MyDrive/Currency/Test/1Hundrednote/*.*\"\n",
        "path2Hundrednote = \"/content/drive/MyDrive/Currency/Test/2Hundrednote/*.*\"\n",
        "path2Thousandnote = \"/content/drive/MyDrive/Currency/Test/2Thousandnote/*.*\"\n",
        "path5Hundrednote = \"/content/drive/MyDrive/Currency/Test/5Hundrednote/*.*\"\n",
        "pathFiftynote = \"/content/drive/MyDrive/Currency/Test/Fiftynote/*.*\"\n",
        "pathTennote = \"/content/drive/MyDrive/Currency/Test/Tennote/*.*\"\n",
        "pathTwentynote = \"/content/drive/MyDrive/Currency/Test/Twentynote/*.*\"\n",
        "\n",
        "\n",
        "#Testing Data  \n",
        "trainingdata1 = readData(path1Hundrednote)\n",
        "trainingdata2 = readData(path2Hundrednote)\n",
        "trainingdata3 = readData(path2Thousandnote)\n",
        "trainingdata4 = readData(path5Hundrednote)\n",
        "trainingdata5 = readData(pathFiftynote)\n",
        "trainingdata6 = readData(pathTennote)\n",
        "trainingdata7 = readData(pathTwentynote)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "allData =[trainingdata1,trainingdata2,trainingdata3,trainingdata4,trainingdata5 ,trainingdata6 , trainingdata7 ]\n",
        "\n",
        "sum = 0 \n",
        "for i in allData :\n",
        "  sum+=len(i)\n",
        "  print(len(i))\n",
        "\n",
        "print(sum)"
      ],
      "metadata": {
        "id": "xzQ9lZyaDhzM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8c3694d-057c-4dea-a5a2-f480d14db2a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "6\n",
            "6\n",
            "6\n",
            "6\n",
            "6\n",
            "6\n",
            "42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainingdata1 = np.array(trainingdata1)\n",
        "trainingdata2 = np.array(trainingdata2)\n",
        "trainingdata3 = np.array(trainingdata3)\n",
        "trainingdata4 = np.array(trainingdata4)\n",
        "trainingdata5 = np.array(trainingdata5)\n",
        "trainingdata6 = np.array(trainingdata6)\n",
        "trainingdata7 = np.array(trainingdata7)\n",
        "\n",
        "\n",
        "\n",
        "augmentData(trainingdata1 ,\"/content/drive/MyDrive/Currency/AUG Test/1\" )\n",
        "augmentData(trainingdata2 ,\"/content/drive/MyDrive/Currency/AUG Test/2\" )\n",
        "augmentData(trainingdata3 ,\"/content/drive/MyDrive/Currency/AUG Test/3\" )\n",
        "augmentData(trainingdata4 ,\"/content/drive/MyDrive/Currency/AUG Test/4\" )\n",
        "augmentData(trainingdata5 ,\"/content/drive/MyDrive/Currency/AUG Test/5\" )\n",
        "augmentData(trainingdata6 ,\"/content/drive/MyDrive/Currency/AUG Test/6\" )\n",
        "augmentData(trainingdata7 ,\"/content/drive/MyDrive/Currency/AUG Test/7\" )"
      ],
      "metadata": {
        "id": "RvtfLra7Jb29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainingdata1 = readData(\"/content/drive/MyDrive/Currency/AUG Test/1/*.*\")\n",
        "trainingdata2 = readData(\"/content/drive/MyDrive/Currency/AUG Test/2/*.*\")\n",
        "trainingdata3 = readData(\"/content/drive/MyDrive/Currency/AUG Test/3/*.*\")\n",
        "trainingdata4 = readData(\"/content/drive/MyDrive/Currency/AUG Test/4/*.*\")\n",
        "trainingdata5 = readData(\"/content/drive/MyDrive/Currency/AUG Test/5/*.*\")\n",
        "trainingdata6 = readData(\"/content/drive/MyDrive/Currency/AUG Test/6/*.*\")\n",
        "trainingdata7 = readData(\"/content/drive/MyDrive/Currency/AUG Test/7/*.*\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "allData =[trainingdata1,trainingdata2,trainingdata3,trainingdata4,trainingdata5 ,trainingdata6 , trainingdata7 ]\n",
        "sum = 0 \n",
        "for i in allData :\n",
        "  sum+=len(i) \n",
        "  print(len(i))\n",
        "\n",
        "print(sum)"
      ],
      "metadata": {
        "id": "TXfhVUgYEMei",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b60786ff-bf8d-4194-816c-c2cd0fb243db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "603\n",
            "600\n",
            "601\n",
            "600\n",
            "603\n",
            "601\n",
            "603\n",
            "4211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vq-Tz37UjAmX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}